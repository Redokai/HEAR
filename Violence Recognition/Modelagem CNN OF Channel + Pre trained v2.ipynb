{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem e arquitetura CNN\n",
    "\n",
    "## Modelo de canal único Optical Flow pré treinado VGG 16 + IMAGENET (Top layers off)\n",
    "\n",
    "### Conteúdo\n",
    "\n",
    "- Ingestão\n",
    "- Pré processamento\n",
    "- Modelagem da rede\n",
    "- Treinamento\n",
    "- Teste\n",
    "- Validação\n",
    "- Resultados\n",
    "\n",
    "### Importações e parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "#tfds.disable_progress_bar()\n",
    "\n",
    "videos_table_path = 'manual_of_classification.csv'\n",
    "max_positive_cases = 5000\n",
    "max_validation_cases = 10000\n",
    "preprocess_training_test = True\n",
    "preprocess_validation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def process_path(file_path):\n",
    "    img = tf.io.read_file(file_path, )\n",
    "    img = decode_img(img)\n",
    "    return img\n",
    "\n",
    "def process_label(label):\n",
    "    return label == 'POS'\n",
    "\n",
    "def process_dataframe(dataframe):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    with tf.device('/cpu:0'):\n",
    "        for i,row in dataframe.iterrows():\n",
    "            path = row['path']\n",
    "            label = row['violence']\n",
    "            xs.append(process_path(path))\n",
    "            ys.append(process_label(label))\n",
    "        return tf.data.Dataset.from_tensor_slices((xs,ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\red\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3051: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test dataset cases :10000\n",
      "Validation dataset cases :30914\n"
     ]
    }
   ],
   "source": [
    "#IMPORT\n",
    "frames_df = pd.read_csv(videos_table_path, sep=';', index_col=0)\n",
    "video_list = frames_df[frames_df['load'] == 'X']['video'].unique()\n",
    "\n",
    "#SEGREGATE\n",
    "msk = np.random.rand(len(video_list)) < 0.9\n",
    "train_test_videos = video_list[msk]\n",
    "validation_videos =  video_list[~msk]\n",
    "train_test_df = frames_df.loc[frames_df['video'].isin(train_test_videos)]\n",
    "validation_df = frames_df.loc[frames_df['video'].isin(validation_videos)]\n",
    "neg_df = train_test_df[train_test_df['violence'] == 'NEG'][['path','violence']]\n",
    "pos_df = train_test_df[train_test_df['violence'] == 'POS'][['path','violence']]\n",
    "\n",
    "#SHUFFLE\n",
    "neg_df = neg_df.sample(frac=1).reset_index(drop=True)\n",
    "pos_df = pos_df.sample(frac=1).reset_index(drop=True)\n",
    "validation_df = validation_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#SAVE\n",
    "validation_df.to_csv('validation_of_df.csv',sep=';')\n",
    "\n",
    "#RESIZE\n",
    "pos_df = pos_df.head(min([len(pos_df),max_positive_cases]))\n",
    "neg_df = neg_df.head(len(pos_df))\n",
    "\n",
    "#MERGE\n",
    "merged_df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
    "dataset_length = len(merged_df)\n",
    "validation_length = len(validation_df)\n",
    "\n",
    "print('Train/test dataset cases :' + str(dataset_length))\n",
    "print('Validation dataset cases :' + str(validation_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('validation_of_df.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observações\n",
    "\n",
    "Dataset claramente tendencioso (biased), será necessário tratar o desbalanceamento na fase de préprocessamento a fim de manter uma RN bem treinada.\n",
    "\n",
    "#### Tarefas\n",
    "- Separação do dataset em:\n",
    "    - Dataset de treinamento (70%)\n",
    "    - Dataset de teste (30%)\n",
    "\n",
    "    \n",
    "OBS: Todos os datasets devem estar balanceados! Portanto a medida balizadora será o gargalo atual: número de casos positivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame size: 7000\n",
      "Test DataFrame size: 3000\n",
      "Validation DataFrame size: 30914\n"
     ]
    }
   ],
   "source": [
    "train_ds = None\n",
    "test_ds = None\n",
    "validation_ds = None\n",
    "\n",
    "#RESHUFLE\n",
    "if preprocess_training_test:\n",
    "    shuffled_df = merged_df.sample(frac=1).reset_index(drop=True)\n",
    "if preprocess_validation:\n",
    "    validation_shuffled_df = validation_df.sample(frac=max_validation_cases/validation_length).reset_index(drop=True)\n",
    "\n",
    "#PROCESS\n",
    "if preprocess_training_test:\n",
    "    complete_dataset = process_dataframe(shuffled_df)\n",
    "if preprocess_validation:\n",
    "    validation_ds = process_dataframe(validation_shuffled_df)\n",
    "\n",
    "#SEPARATE\n",
    "if preprocess_training_test:\n",
    "    train_ds = complete_dataset.take(int(dataset_length*0.7))\n",
    "    test_ds = complete_dataset.skip(int(dataset_length*0.7))\n",
    "\n",
    "print('Train DataFrame size: ' + str(int(dataset_length*0.7)))\n",
    "print('Test DataFrame size: ' + str(dataset_length - int(dataset_length*0.7)))\n",
    "print('Validation DataFrame size: ' + str(int(validation_length)))\n",
    "\n",
    "### Clear unused data\n",
    "frames_df = None\n",
    "neg_df = None\n",
    "pos_df = None\n",
    "#merged_df = None\n",
    "shuffled_df = None\n",
    "complete_dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = train_ds.shuffle(60).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelagem da CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model VGG16\n",
    "IMG_SIZE = 224\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "model = tf.keras.models.Sequential()\n",
    "for layer in base_model.layers:\n",
    "    model.add(layer)\n",
    "    \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "flatten_layer = tf.keras.layers.Flatten()\n",
    "dropout_layer = tf.keras.layers.Dropout(0.5)\n",
    "dense_layer = tf.keras.layers.Dense(4096, activation='relu')\n",
    "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "model.add(flatten_layer)\n",
    "#model.add(dropout_layer)\n",
    "model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "#model.add(dropout_layer)\n",
    "model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "model.add(prediction_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'), tf.keras.metrics.Precision(name='precision'),tf.keras.metrics.Recall(name='recall')]) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 134,264,641\n",
      "Trainable params: 119,549,953\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\red\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: cnn_vgg16_pretrainned_dense_of_v2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('cnn_vgg16_pretrainned_dense_of_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar modelo\n",
    "\n",
    "- OBS : Lembrar de ligar GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('cnn_vgg16_pretrainned_dense_of_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento\n",
    "\n",
    "Utilizando o dataset de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-3e6ddb0f8653>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Train for 219 steps\n",
      "Epoch 1/100\n",
      "219/219 [==============================] - 47s 216ms/step - loss: 0.6937 - accuracy: 0.4984 - precision: 0.4062 - recall: 0.0037\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 43s 194ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 43s 194ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 42s 193ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 41s 189ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 41s 189ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 41s 187ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 41s 187ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 41s 187ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 41s 187ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 41s 187ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 41s 188ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 41s 187ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 41s 186ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 41s 185ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 42s 190ms/step - loss: 0.6931 - accuracy: 0.4993 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 42/100\n",
      "139/219 [==================>...........] - ETA: 16s - loss: 0.6931 - accuracy: 0.5058 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_batches, epochs=100)#, callbacks=[ tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_vgg16_pretrainned_dense_of_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.777\n",
      "\n",
      "Test precision: 0.83388704\n",
      "\n",
      "Test recall: 0.6816022\n"
     ]
    }
   ],
   "source": [
    "#test_batch = test_ds.batch(150)\n",
    "#with tf.device('/cpu:0'):\n",
    "features = np.array([list(x[0].numpy()) for x in list(test_ds)])\n",
    "labels = np.array([x[1].numpy() for x in list(test_ds)])\n",
    "test_loss, test_acc, test_prec, test_rec = model.evaluate(x=features, y=labels, verbose=0)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "print('\\nTest precision:', test_prec)\n",
    "print('\\nTest recall:', test_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([list(x[0].numpy()) for x in list(validation_ds)])\n",
    "labels = np.array([x[1].numpy() for x in list(validation_ds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.8703\n",
      "\n",
      "Validation precision: 0.12673056\n",
      "\n",
      "Validation recall: 0.19966443\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_prec, test_rec = model.evaluate(x=features, y=labels, verbose=0)\n",
    "\n",
    "print('\\nValidation accuracy:', test_acc)\n",
    "print('\\nValidation precision:', test_prec)\n",
    "print('\\nValidation recall:', test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation accuracy: 0.8637\n",
      "\n",
      "Validation precision: 0.23934427\n",
      "\n",
      "Validation recall: 0.4016506\n"
     ]
    }
   ],
   "source": [
    "print('\\nValidation accuracy:', test_acc)\n",
    "print('\\nValidation precision:', test_prec)\n",
    "print('\\nValidation recall:', test_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_labels = [int(x) for x in labels]\n",
    "predictions = model.predict_classes(features, batch_size=None)\n",
    "pred = [x[0] for x in list(predictions)]\n",
    "mat = tf.math.confusion_matrix(c_labels, pred)\n",
    "df = pd.DataFrame(mat.numpy(), columns=['AP','AN'], index=['PP','PN'])\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.heatmap(df, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=['Negative','Positive'], yticklabels=['Negative','Positive'])\n",
    "ax.set_ylim([2,0])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('VGG16 Raw RGB, Test Dataset Evaluation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\red\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: cnn_vgg16_pretrainned_dense_of\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('cnn_vgg16_pretrainned_dense_of')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
